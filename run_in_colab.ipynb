{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67e8fad",
   "metadata": {},
   "source": [
    "# Run `run.py` in Google Colab\n",
    "Install dependencies, clone the repository if needed, and launch the training or evaluation script with parameterized arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a30504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_url = \"https://github.com/Chris0lsen/fp-dataset-artifacts.git\"\n",
    "repo_dir = Path(\"fp-dataset-artifacts\")\n",
    "\n",
    "if Path.cwd().name != repo_dir.name:\n",
    "    if not repo_dir.exists():\n",
    "        subprocess.run([\"git\", \"clone\", repo_url, repo_dir.name], check=True)\n",
    "    os.chdir(repo_dir)\n",
    "    print(f\"Working directory: {Path.cwd()}\")\n",
    "else:\n",
    "    print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84aa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these values as needed.\n",
    "task = \"nli\"\n",
    "dataset = \"snli\"\n",
    "do_train = True\n",
    "do_eval = False\n",
    "output_dir = \"./trained_model\"\n",
    "model_id = \"google/electra-small-discriminator\"\n",
    "max_length = 128\n",
    "max_train_samples = None\n",
    "max_eval_samples = None\n",
    "training_arg_overrides = {\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"num_train_epochs\": 3.0\n",
    "}\n",
    "extra_args = []  # e.g., [\"--resume_from_checkpoint\", \"./trained_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "cli_args = [\n",
    "    sys.executable,\n",
    "    \"run.py\",\n",
    "    \"--task\",\n",
    "    task,\n",
    "    \"--output_dir\",\n",
    "    output_dir\n",
    "]\n",
    "\n",
    "if do_train:\n",
    "    cli_args.append(\"--do_train\")\n",
    "if do_eval:\n",
    "    cli_args.append(\"--do_eval\")\n",
    "if dataset:\n",
    "    cli_args.extend([\"--dataset\", dataset])\n",
    "if model_id:\n",
    "    cli_args.extend([\"--model\", model_id])\n",
    "if max_length is not None:\n",
    "    cli_args.extend([\"--max_length\", str(max_length)])\n",
    "if max_train_samples is not None:\n",
    "    cli_args.extend([\"--max_train_samples\", str(max_train_samples)])\n",
    "if max_eval_samples is not None:\n",
    "    cli_args.extend([\"--max_eval_samples\", str(max_eval_samples)])\n",
    "\n",
    "for key, value in training_arg_overrides.items():\n",
    "    if value is None:\n",
    "        continue\n",
    "    cli_args.extend([f\"--{key}\", str(value)])\n",
    "\n",
    "cli_args.extend(extra_args)\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Running:\", \" \".join(shlex.quote(str(arg)) for arg in cli_args))\n",
    "subprocess.run(cli_args, check=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
