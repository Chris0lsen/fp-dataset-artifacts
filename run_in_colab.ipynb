{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67e8fad",
   "metadata": {},
   "source": [
    "# Run `run.py` in Google Colab\n",
    "Install dependencies, clone the repository if needed, and launch the training or evaluation script with parameterized arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a30504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_url = \"https://github.com/Chris0lsen/fp-dataset-artifacts.git\"\n",
    "repo_dir = Path(\"fp-dataset-artifacts\")\n",
    "\n",
    "if Path.cwd().name != repo_dir.name:\n",
    "    if not repo_dir.exists():\n",
    "        subprocess.run([\"git\", \"clone\", repo_url, repo_dir.name], check=True)\n",
    "    os.chdir(repo_dir)\n",
    "    print(f\"Working directory: {Path.cwd()}\")\n",
    "else:\n",
    "    print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84aa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these values as needed.\n",
    "task = \"nli\"\n",
    "dataset = \"snli\"\n",
    "do_train = True\n",
    "do_eval = False\n",
    "output_dir = \"./trained_model\"\n",
    "model_id = \"google/electra-small-discriminator\"\n",
    "max_length = 128\n",
    "max_train_samples = None\n",
    "max_eval_samples = None\n",
    "training_arg_overrides = {\n",
    "    \"per_device_train_batch_size\": 8,\n",
    "    \"num_train_epochs\": 3.0\n",
    "}\n",
    "extra_args = []  # e.g., [\"--resume_from_checkpoint\", \"./trained_model\"]\n",
    "disable_wandb = True  # Set to False if you have wandb configured\n",
    "keep_intermediate_checkpoints = False  # When False, disable periodic checkpoint saves\n",
    "save_to_drive = False  # Flip to True to copy artifacts into Google Drive after a run\n",
    "drive_mount_point = \"/content/drive\"  # Leave as-is unless you mount elsewhere\n",
    "drive_output_dir = \"/content/drive/MyDrive/fp-trained-models\"  # Destination folder in Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "cli_args = [\n",
    "    sys.executable,\n",
    "    \"run.py\",\n",
    "    \"--task\",\n",
    "    task,\n",
    "    \"--output_dir\",\n",
    "    output_dir\n",
    "]\n",
    "\n",
    "if do_train:\n",
    "    cli_args.append(\"--do_train\")\n",
    "if do_eval:\n",
    "    cli_args.append(\"--do_eval\")\n",
    "if dataset:\n",
    "    cli_args.extend([\"--dataset\", dataset])\n",
    "if model_id:\n",
    "    cli_args.extend([\"--model\", model_id])\n",
    "if max_length is not None:\n",
    "    cli_args.extend([\"--max_length\", str(max_length)])\n",
    "if max_train_samples is not None:\n",
    "    cli_args.extend([\"--max_train_samples\", str(max_train_samples)])\n",
    "if max_eval_samples is not None:\n",
    "    cli_args.extend([\"--max_eval_samples\", str(max_eval_samples)])\n",
    "\n",
    "effective_overrides = dict(training_arg_overrides)\n",
    "if not keep_intermediate_checkpoints:\n",
    "    effective_overrides.setdefault(\"save_strategy\", \"no\")\n",
    "\n",
    "for key, value in effective_overrides.items():\n",
    "    if value is None:\n",
    "        continue\n",
    "    cli_args.extend([f\"--{key}\", str(value)])\n",
    "\n",
    "cli_args.extend(extra_args)\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = os.environ.copy()\n",
    "if disable_wandb:\n",
    "    env[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "if save_to_drive:\n",
    "    try:\n",
    "        from google.colab import drive as gdrive\n",
    "    except ImportError as exc:\n",
    "        raise RuntimeError(\"save_to_drive=True requires running inside Google Colab\") from exc\n",
    "    print(f\"Mounting Google Drive at {drive_mount_point} (you may be prompted to authorize)...\")\n",
    "    gdrive.mount(drive_mount_point, force_remount=False)\n",
    "\n",
    "print(\"Running:\", \" \".join(shlex.quote(str(arg)) for arg in cli_args))\n",
    "result = subprocess.run(cli_args, check=False, capture_output=True, text=True, env=env)\n",
    "if result.stdout:\n",
    "    print(\"\\nstdout:\\n\", result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nstderr:\\n\", result.stderr, file=sys.stderr)\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"run.py exited with status {result.returncode}\")\n",
    "\n",
    "if save_to_drive:\n",
    "    source_dir = Path(output_dir)\n",
    "    if not source_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"Expected output directory '{source_dir}' not found\")\n",
    "    dest_root = Path(drive_output_dir)\n",
    "    dest_root.mkdir(parents=True, exist_ok=True)\n",
    "    dest_dir = dest_root / source_dir.name\n",
    "    print(f\"Copying artifacts to {dest_dir}...\")\n",
    "    shutil.copytree(source_dir, dest_dir, dirs_exist_ok=True)\n",
    "    print(\"Artifacts copied to Google Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Use the fine-tuned checkpoint unless you override here\n",
    "eval_model_path = Path(output_dir)\n",
    "if not eval_model_path.exists():\n",
    "    eval_model_path = Path(model_id)\n",
    "\n",
    "cli_args = [\n",
    "    sys.executable,\n",
    "    \"run.py\",\n",
    "    \"--task\",\n",
    "    task,\n",
    "    \"--output_dir\",\n",
    "    output_dir,\n",
    "    \"--do_eval\"\n",
    "]\n",
    "\n",
    "if dataset:\n",
    "    cli_args.extend([\"--dataset\", dataset])\n",
    "if eval_model_path:\n",
    "    cli_args.extend([\"--model\", str(eval_model_path)])\n",
    "if max_length is not None:\n",
    "    cli_args.extend([\"--max_length\", str(max_length)])\n",
    "if max_eval_samples is not None:\n",
    "    cli_args.extend([\"--max_eval_samples\", str(max_eval_samples)])\n",
    "\n",
    "per_device_eval_bs = training_arg_overrides.get(\"per_device_eval_batch_size\")\n",
    "if per_device_eval_bs is not None:\n",
    "    cli_args.extend([\"--per_device_eval_batch_size\", str(per_device_eval_bs)])\n",
    "\n",
    "cli_args.extend(extra_args)\n",
    "\n",
    "env = os.environ.copy()\n",
    "if disable_wandb:\n",
    "    env[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "print(\"Running eval:\", \" \".join(shlex.quote(str(arg)) for arg in cli_args))\n",
    "result = subprocess.run(cli_args, check=False, capture_output=True, text=True, env=env)\n",
    "if result.stdout:\n",
    "    print(\"\\nstdout:\\n\", result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nstderr:\\n\", result.stderr, file=sys.stderr)\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"run.py evaluation exited with status {result.returncode}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
